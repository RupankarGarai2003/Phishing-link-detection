{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df=pd.read_csv(\"Malicious URLs.csv\")\n",
    "feedback_url_df = pd.read_csv(\"feedback_url_df.csv\") if os.path.exists(\"user_feedback.csv\") else pd.DataFrame(columns=['URLs', 'Class'])\n",
    "test_url=url_df[\"URLs\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     URLs Class\n",
      "0                         freebase.com/view/en/bob_sirois  good\n",
      "1                          en.wikipedia.org/wiki/Joie_Lee  good\n",
      "2                pipl.com/directory/people/Rejean/Beaudin  good\n",
      "3       flickr.com/photos/teneyck/sets/72157610336209297/  good\n",
      "4       ussoccer.com/News/Federation-Services/2009/06/...  good\n",
      "...                                                   ...   ...\n",
      "420459  ourorigins.org/genealogielistfirstname.aspx?an...  good\n",
      "420460    simira.co.id/cifk/live.com/Account_Verified.htm   bad\n",
      "420461  kstatesports.com/sports/w-baskbl/spec-rel/ksu-...  good\n",
      "420462  vh1.com/video/living-colour/9128/cult-of-perso...  good\n",
      "420463     absoluteastronomy.com/topics/SummerSlam_(1990)  good\n",
      "\n",
      "[420464 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(url_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percentage=.2\n",
    "train_df,test_df=train_test_split(url_df,test_size=test_percentage,random_state=42)\n",
    "labels=train_df[\"Class\"]\n",
    "test_labels=test_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples 336371\n",
      "Testing Samples 84093\n"
     ]
    }
   ],
   "source": [
    "#graphical representation of data\n",
    "print(\"Training Samples\",len(train_df))\n",
    "print(\"Testing Samples\",len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ussoccer', 'News', 'Federation', 'Services', '2009', '06', 'University', 'Of', 'Miami', 'President', 'Donna', 'E', 'Shalala', 'Joins', 'Team', 'To', 'Bring', 'FIFA', 'World', 'Cup', 'To', 'United', 'States', 'In', 'aspx']\n"
     ]
    }
   ],
   "source": [
    "# Splits the urls and make tokens\n",
    "def tokenizer(url):\n",
    "    tokens = re.split(r'[\\./-]', url)\n",
    "    common_substrings = ['com', 'www']\n",
    "    tokens = [token for token in tokens if token not in common_substrings]\n",
    "\n",
    "    return tokens\n",
    "tokenized_url=tokenizer(test_url)\n",
    "print(tokenized_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tvec.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Vectorize the training inputs with CountVectorizer\n",
    "count_vec = CountVectorizer(analyzer=tokenizer)\n",
    "count_x = count_vec.fit_transform(train_df['URLs'])\n",
    "\n",
    "# Vectorize the training inputs with TfidfVectorizer\n",
    "tVec = TfidfVectorizer(analyzer=tokenizer)\n",
    "tfidf_x = tVec.fit_transform(train_df['URLs'])\n",
    "dump(tVec, 'tvec.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count_x=count_vec.transform(test_df['URLs'])\n",
    "test_tfid_x=tVec.transform(test_df['URLs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.98      0.91      0.94     15136\n",
      "        good       0.98      1.00      0.99     68957\n",
      "\n",
      "    accuracy                           0.98     84093\n",
      "   macro avg       0.98      0.95      0.96     84093\n",
      "weighted avg       0.98      0.98      0.98     84093\n",
      "\n",
      "Accuracy: 0.9792729478077843\n",
      "Confusion Matrix:\n",
      "[[13729  1407]\n",
      " [  336 68621]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.98      0.91      0.94     15136\n",
      "        good       0.98      1.00      0.99     68957\n",
      "\n",
      "    accuracy                           0.98     84093\n",
      "   macro avg       0.98      0.95      0.96     84093\n",
      "weighted avg       0.98      0.98      0.98     84093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model with Multinomial naive Bayesian with TF-IDF\n",
    "mnb_tfidf=MultinomialNB(alpha=.1)\n",
    "mnb_tfidf.fit(tfidf_x,labels)\n",
    "# Now test and evaluate the model\n",
    "score_mnb_tfidf=mnb_tfidf.score(test_tfid_x,test_labels)\n",
    "predictions_mnb_tfidf=mnb_tfidf.predict(test_tfid_x)\n",
    "cmarix_mnb_tdidf=confusion_matrix(test_labels,predictions_mnb_tfidf)\n",
    "classification_report_mnb_tfidf=classification_report(test_labels,predictions_mnb_tfidf)\n",
    "print(classification_report_mnb_tfidf)\n",
    "print(f\"Accuracy: {score_mnb_tfidf}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cmarix_mnb_tdidf)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_mnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnb_tfidf_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the model\n",
    "dump(mnb_tfidf, 'mnb_tfidf_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['good']\n",
      "The link has low probability of being malicious.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from joblib import load\n",
    "\n",
    "# Load the trained model\n",
    "mnb_tfidf = load('mnb_tfidf_model.joblib')\n",
    "\n",
    "# Load the TF-IDF vectorizer used during training\n",
    "tfidf_vectorizer = load('tvec.joblib')  # Use the correct file name\n",
    "\n",
    "# Assuming user_input is the link provided by the user\n",
    "user_input = str(input(\"Enter the link you want to check: \"))\n",
    "\n",
    "# Vectorize the user input using the same TF-IDF vectorizer used during training\n",
    "user_input_vectorized = tfidf_vectorizer.transform([user_input])\n",
    "\n",
    "# Predict using the loaded model\n",
    "prediction = mnb_tfidf.predict(user_input_vectorized)\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Prediction:\", prediction)\n",
    "\n",
    "if prediction == \"bad\":\n",
    "    print(\"The link has high probability of being malicious.\")\n",
    "else:\n",
    "    print(\"The link has low probability of being malicious.\")\n",
    "\n",
    "# If the prediction is incorrect, ask for the correct label and update the database\n",
    "if user_input not in url_df['URLs'].values:\n",
    "    feedback = input(\"Is the prediction correct? (yes/no): \")\n",
    "\n",
    "    # If the prediction is incorrect, ask for the correct label and update the feedback dataset\n",
    "    if feedback.lower() == \"no\":\n",
    "        correct_label = input(\"Enter the correct label (good/bad): \")\n",
    "        new_entry = pd.DataFrame({'URLs': [user_input], 'Class': [correct_label]})\n",
    "        feedback_url_df = pd.concat([feedback_url_df, new_entry], ignore_index=True)\n",
    "        feedback_url_df.to_csv(\"feedback_url_df.csv\", index=False)\n",
    "        print(\"Feedback recorded.\")\n",
    "else:\n",
    "    print(\"The link is in the original dataset. No feedback required.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
